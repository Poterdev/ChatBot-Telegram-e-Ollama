{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7509e4da-5e1f-46cb-b6de-98fa441841e7",
   "metadata": {},
   "source": [
    "# Chatbot IA para Vendas de Carros\n",
    "## Sistema Integrado Telegram + RAG + LLM Local (OLLAMA)\n",
    "\n",
    "Este notebook implementa um chatbot inteligente para vendas de carros usando Telegram como interface, RAG (Retrieval Augmented Generation) para contexto e LLM local para processamento de linguagem natural.\n",
    "\n",
    "\n",
    "### 1. Configura√ß√£o do Ambiente\n",
    "\n",
    "Primeiro, precisamos instalar todas as depend√™ncias necess√°rias para o projeto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3278bd43-b735-4a92-98fb-58a152934b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala√ß√£o das bibliotecas necess√°rias\n",
    "!pip install pyTelegramBotAPI\n",
    "!pip install llama-index\n",
    "!pip install python-telegram-bot --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45770b80-363f-47d1-bc31-3678ff731b46",
   "metadata": {},
   "source": [
    "### 2. Importa√ß√µes e Configura√ß√µes Iniciais\n",
    "\n",
    "Importamos todas as bibliotecas necess√°rias para o projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce88249-ac93-4abc-bae5-4bbeaa9f80b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import telebot\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.prompts import ChatPromptTemplate, PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7aca2b-ea69-4f73-9ca5-8cf1c234a907",
   "metadata": {},
   "source": [
    "### 3. Configura√ß√£o do Bot Telegram\n",
    "\n",
    "Configure seu bot Telegram usando o token obtido do BotFather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3431d1bf-12a3-4c4b-a65d-a739a6ad7cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√£o do token do bot\n",
    "bot_key = 'SEU_TOKEN_AQUI'\n",
    "bot = telebot.TeleBot(bot_key, parse_mode=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6b2187-7d18-48c7-b196-a78fa1571d79",
   "metadata": {},
   "source": [
    "### 4. Configura√ß√£o do Sistema LLM e Embeddings\n",
    "\n",
    "Configuramos o modelo LLM local e o sistema de embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e60a675-4d63-4070-98cb-396b3c92f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√£o do LLM e embeddings\n",
    "Settings.llm = Ollama(model=\"llama3.2\", request_timeout=120.0)\n",
    "Settings.embed_model = OllamaEmbedding(\n",
    "    model_name=\"nomic-embed-text\",\n",
    "    base_url=\"http://localhost:11434\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682a2b00-a307-42ae-891c-19e46ff611ef",
   "metadata": {},
   "source": [
    "### 5. Carregamento e Indexa√ß√£o dos Dados\n",
    "\n",
    "Carregamos os documentos e criamos o √≠ndice vetorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6708378-cad5-4045-aaf9-58f2fd72139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento dos documentos\n",
    "data = SimpleDirectoryReader(input_dir=\"./data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d0aaac-1429-40eb-9f19-d1746666594f",
   "metadata": {},
   "source": [
    "### 6. Configura√ß√£o dos Prompts\n",
    "\n",
    "Definimos os prompts que ser√£o usados pelo sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579f3d1c-54d4-4cc5-a2da-c1a210d5760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt principal para o assistente de vendas\n",
    "qa_prompt_str = (\n",
    "    \"As informa√ß√µes de contexto est√£o abaixo.\\n\"\n",
    "    \"Seu nome √© uma Assistente de vendas.\\n\"\n",
    "    \"Est√° oferecendo um carro usado e n√£o novo. \\n\"\n",
    "    \"Seja simp√°tico.\\n\"\n",
    "    \"Responda sempre em portugu√™s.\\n\"\n",
    "    \"Haja como se voc√™ estivesse vendendo o Siena 1.4, ano 2010, baseado na base de dados fornecida.\\n\"\n",
    "    \"No final de cada resposta, lembre o cliente que para negocia√ß√µes reais, utilize o comando /help para obter o contato do vendedor.\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Dadas as informa√ß√µes de contexto, responda √† pergunta de forma breve: {query_str}\\n\"\n",
    ")\n",
    "\n",
    "qa_prompt = PromptTemplate(qa_prompt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d94bf2-a07c-466f-9406-038a6a4bdd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template de refinamento\n",
    "refine_template_str = (\n",
    "    \"responda a {query_str} com uma resposta breve\"\n",
    "    \" Seja fiel a sua base de dados.\"\n",
    "    \" N√ÉO INVENTE VALORES OU PROPOSTA\"\n",
    "    \" N√ÉO FECHE NEGOCIO DIRECIONE AO /help PARA FECHAR E MARCAR VISITA\"\n",
    ")\n",
    "refine_template = PromptTemplate(refine_template_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59eda2d-ffff-4669-bb85-b406a47403d4",
   "metadata": {},
   "source": [
    "### 7. Configura√ß√£o do Motor de Consulta\n",
    "\n",
    "Configuramos o motor que processar√° as consultas dos usu√°rios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564cfcb6-f640-405b-a000-744de3c08c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√£o do query engine\n",
    "query_engine = index.as_query_engine(\n",
    "    text_qa_template=qa_prompt,\n",
    "    refine_template=refine_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82440664-c2bc-43a8-8150-a42539afa836",
   "metadata": {},
   "source": [
    "### 8. Implementa√ß√£o dos Handlers do Bot\n",
    "\n",
    "Implementamos os handlers que processar√£o as mensagens do Telegram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cee3450-589f-409a-b0d5-a2cb48acf58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handler de boas-vindas\n",
    "@bot.message_handler(commands=['start'])\n",
    "def send_welcome(message):\n",
    "    bot.reply_to(message, \"\"\"\n",
    "    Ol√°! Sou um bot que pode responder perguntas baseadas nos documentos carregados.\n",
    "    Digite sua pergunta e farei o poss√≠vel para respond√™-la.\n",
    "    \"\"\")\n",
    "\n",
    "# Handler principal para processamento de mensagens\n",
    "@bot.message_handler(func=lambda message: True)\n",
    "def handle_query(message):\n",
    "    try:\n",
    "        # Mensagem de processamento\n",
    "        processing_msg = bot.reply_to(message, \"Processando sua pergunta...\")\n",
    "        \n",
    "        # Obt√©m resposta do LLM\n",
    "        response = query_engine.query(message.text)\n",
    "        \n",
    "        # Envia resposta\n",
    "        bot.edit_message_text(\n",
    "            chat_id=message.chat.id,\n",
    "            message_id=processing_msg.message_id,\n",
    "            text=str(response)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        bot.edit_message_text(\n",
    "            chat_id=message.chat.id,\n",
    "            message_id=processing_msg.message_id,\n",
    "            text=f\"Desculpe, ocorreu um erro: {str(e)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431d4d0e-3e0a-4101-bef8-badf7e7d7a89",
   "metadata": {},
   "source": [
    "### 9. Iniciando o Bot\n",
    "\n",
    "Finalmente, iniciamos o bot para come√ßar a processar mensagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1baade3-c427-4863-b567-ddd2a00cb1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Bot iniciado...\")\n",
    "    bot.polling()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbe0b64-c253-4d24-926e-feb4bb24f177",
   "metadata": {},
   "source": [
    "### Estrutura de Diret√≥rios\n",
    "\n",
    "Para que o projeto funcione corretamente, mantenha a seguinte estrutura:\n",
    "\n",
    "```\n",
    "projeto/\n",
    "‚îú‚îÄ‚îÄ data/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ [seus arquivos de dados]\n",
    "‚îú‚îÄ‚îÄ notebook.ipynb\n",
    "‚îî‚îÄ‚îÄ README.md\n",
    "```\n",
    "\n",
    "### Notas Importantes\n",
    "\n",
    "1. **Seguran√ßa**:\n",
    "   - Nunca compartilhe seu token do bot\n",
    "   - Mantenha seus dados sens√≠veis em vari√°veis de ambiente\n",
    "   - Fa√ßa backup regular da base de dados\n",
    "\n",
    "2. **Manuten√ß√£o**:\n",
    "   - Atualize regularmente as bibliotecas\n",
    "   - Monitore o uso de recursos\n",
    "   - Fa√ßa backup dos logs importantes\n",
    "\n",
    "3. **Customiza√ß√£o**:\n",
    "   - Ajuste os prompts conforme necess√°rio\n",
    "   - Adicione novos comandos conforme a demanda\n",
    "   - Mantenha a base de dados atualizada\n",
    "\n",
    "### Troubleshooting\n",
    "\n",
    "Problemas comuns e solu√ß√µes:\n",
    "\n",
    "1. **Erro de conex√£o com Ollama**:\n",
    "   - Verifique se o servi√ßo est√° rodando\n",
    "   - Confirme a URL base\n",
    "   - Verifique as portas\n",
    "\n",
    "2. **Erro no Telegram**:\n",
    "   - Verifique o token\n",
    "   - Confirme as permiss√µes do bot\n",
    "   - Verifique a conex√£o com a API\n",
    "\n",
    "3. **Problemas com RAG**:\n",
    "   - Verifique a estrutura dos documentos\n",
    "   - Confirme o formato dos dados\n",
    "   - Verifique os logs de indexa√ß√£o\n",
    "\n",
    "### Pr√≥ximos Passos\n",
    "\n",
    "Abaixo um codigo completo em python de uma possivel implementa√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17449e22-d47c-462d-b2c9-aa97b40726e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "import telebot\n",
    "from telebot import types\n",
    "from telebot.handler_backends import State, StatesGroup\n",
    "from telebot.storage import StateMemoryStorage\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "class EnhancedTelegramBot:\n",
    "    def __init__(self, bot_token, data_dir=\"./data\"):\n",
    "        self.bot = telebot.TeleBot(bot_token, parse_mode='HTML')\n",
    "        self.data_dir = data_dir\n",
    "        self.conversation_history = {}\n",
    "        self.photo_requests = set()\n",
    "        self.whatsapp_number = \"aqui\"  # Substitua aqui com seu contato.\n",
    "        self.chat_mode = {}  \n",
    "        self.setup_llm()\n",
    "        self.setup_custom_prompts()\n",
    "        self.load_index()\n",
    "        self.setup_handlers()\n",
    "    \n",
    "    def setup_llm(self):\n",
    "        \"\"\"Configura√ß√£o do LLM e modelo de embeddings\"\"\"\n",
    "        Settings.llm = Ollama(model=\"llama3.2\", request_timeout=120.0)\n",
    "        Settings.embed_model = OllamaEmbedding(\n",
    "            model_name=\"nomic-embed-text\",\n",
    "            base_url=\"http://localhost:11434\"\n",
    "        )\n",
    "        Settings.num_output = 256\n",
    "        Settings.context_window = 4096\n",
    "    \n",
    "    def setup_custom_prompts(self):\n",
    "        \"\"\"Configura os prompts personalizados\"\"\"\n",
    "        qa_prompt_str = (\n",
    "            \"As informa√ß√µes de contexto est√£o abaixo.\\n\"\n",
    "            \"Seu nome √© uma Assistente de vendas.\\n\"\n",
    "            \"Est√° oferecendo um carro usado e n√£o novo. \\n\"\n",
    "            \"Seja simp√°tico.\\n\"\n",
    "            \"Responda sempre em portugu√™s.\\n\"\n",
    "            \"Haja como se voc√™ estivesse vendendo o Siena 1.4, ano 2010, baseado na base de dados fornecida.\\n\"\n",
    "            \"No final de cada resposta, lembre o cliente que para negocia√ß√µes reais, utilize o comando /help para obter o contato do vendedor.\\n\"\n",
    "            \"{context_str}\\n\"\n",
    "            \"---------------------\\n\"\n",
    "            \"Dadas as informa√ß√µes de contexto, responda √† pergunta de forma breve: {query_str}\\n \"\n",
    "            \"Se o usu√°rio estiver perguntando sobre imagens ou fotos, sugira usar o comando /Fotos.\\n\"\n",
    "        )\n",
    "        \n",
    "        self.qa_prompt = PromptTemplate(qa_prompt_str)\n",
    "\n",
    "        refine_template_str = (\n",
    "        \"responda a {query_str} com uma resposta breve\"\n",
    "        \" Seja fiel a sua base de dados.r\"\n",
    "        \" N√ÉO INVENTE VALORES OU PROPOSTA\"\n",
    "        \" N√ÉO FECHE NEGOCIO DIRECIONE AO /help PARA FECHAR E MARCAR VISITA\"\n",
    "        )\n",
    "        self.refine_template = PromptTemplate(refine_template_str)\n",
    "        \n",
    "#----------------------------------------------------------------------------------    \n",
    "    \n",
    "    def load_index(self):\n",
    "        \"\"\"Carrega ou recria o √≠ndice de documentos\"\"\"\n",
    "        try:\n",
    "            data = SimpleDirectoryReader(input_dir=self.data_dir).load_data()\n",
    "            self.index = VectorStoreIndex.from_documents(data)\n",
    "            self.query_engine = self.index.as_query_engine(\n",
    "                text_qa_template=self.qa_prompt,refine_template=self.refine_template\n",
    "            )\n",
    "            print(\"‚úÖ Base de dados carregada com sucesso!\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro ao carregar √≠ndice: {e}\")\n",
    "            self.index = None\n",
    "            self.query_engine = None\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "    \n",
    "    def setup_handlers(self):\n",
    "        \"\"\"Configura todos os handlers do bot\"\"\"\n",
    "        \n",
    "        @self.bot.message_handler(commands=['start'])\n",
    "        def start(message):\n",
    "            welcome_text = \"\"\"\n",
    "                üöó Bem-vindo ao Assistente Virtual de Vendas!\n",
    "\n",
    "                Sou uma IA especializada em fornecer informa√ß√µes sobre o Siena 1.4 2010.\n",
    "                \n",
    "                Comandos dispon√≠veis:\n",
    "                /help - Contato do vendedor via WhatsApp\n",
    "                /Fotos - Visualizar fotos do ve√≠culo\n",
    "                /chat - Conversar com a IA sobre o ve√≠culo\n",
    "                /menu - Voltar ao menu principal\n",
    "                \n",
    "                ‚ö†Ô∏è Importante: Sou apenas informativo. Para negocia√ß√µes e visitas, use /help para contatar o vendedor.\n",
    "                \n",
    "                Como posso ajudar voc√™ hoje?\n",
    "            \n",
    "            \"\"\"\n",
    "            self.chat_mode[message.chat.id] = False  # Desativa modo chat\n",
    "            self.bot.reply_to(message, welcome_text)\n",
    "\n",
    "        @self.bot.message_handler(commands=['help'])\n",
    "        def help(message):\n",
    "            help_text = f\"\"\"\n",
    "üì± <b>Contato do Vendedor</b>\n",
    "\n",
    "Para negocia√ß√µes, visitas ou mais informa√ß√µes, entre em contato via WhatsApp:\n",
    "\n",
    "wa.me/{self.whatsapp_number}\n",
    "\n",
    "Hor√°rio de atendimento: 8h √†s 18h\n",
    "            \"\"\"\n",
    "            \n",
    "            self.bot.reply_to(message, help_text)\n",
    "\n",
    "        @self.bot.message_handler(commands=['menu'])\n",
    "        def menu(message):\n",
    "            self.chat_mode[message.chat.id] = False  # Desativa modo chat\n",
    "            menu_text = \"\"\"\n",
    "üîÑ Menu Principal\n",
    "\n",
    "Escolha uma op√ß√£o:\n",
    "/help - Contato do vendedor\n",
    "/Fotos - Ver fotos do ve√≠culo\n",
    "/chat - Conversar com a IA\n",
    "\n",
    "‚ö†Ô∏è Lembre-se: Sou apenas informativo.\n",
    "            \"\"\"\n",
    "            self.bot.reply_to(message, menu_text)\n",
    "\n",
    "        @self.bot.message_handler(commands=['chat'])\n",
    "        def start_chat(message):\n",
    "            if not self.query_engine:\n",
    "                self.bot.reply_to(message, \n",
    "                    \"‚ùå Sistema n√£o inicializado. Aguarde um momento e tente novamente.\")\n",
    "                self.load_index()  # Tenta recarregar o √≠ndice\n",
    "                return\n",
    "                \n",
    "            self.chat_mode[message.chat.id] = True  # Ativa modo chat\n",
    "            chat_intro = \"\"\"\n",
    "üí¨ Modo Conversa Ativado!\n",
    "\n",
    "Agora voc√™ pode me fazer perguntas sobre o Siena 1.4 2010.\n",
    "Responderei suas d√∫vidas baseado nas informa√ß√µes dispon√≠veis sobre:\n",
    "- Caracter√≠sticas do ve√≠culo\n",
    "- Estado de conserva√ß√£o est√©tica\n",
    "- Estado de conserva√ß√£o mec√¢nica\n",
    "- Documenta√ß√£o\n",
    "- Proposta\n",
    "\n",
    "Use /menu para voltar ao menu principal.\n",
    "\n",
    "Como posso ajudar?\n",
    "            \"\"\"\n",
    "            self.bot.reply_to(message, chat_intro)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "        \n",
    "        @self.bot.message_handler(commands=['Fotos'])\n",
    "        def gallery(message):\n",
    "            try:\n",
    "                photo_dir = \"./imagens_est√©tica\"  # Diret√≥rio com as fotos\n",
    "                photos = [f for f in os.listdir(photo_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "                \n",
    "                if not photos:\n",
    "                    self.bot.reply_to(message, \"Desculpe, n√£o h√° fotos dispon√≠veis no momento.\")\n",
    "                    return\n",
    "                \n",
    "                # Envia fotos individualmente\n",
    "                for photo in photos[:10]:  # Limita a 10 fotos\n",
    "                    try:\n",
    "                        with open(os.path.join(photo_dir, photo), 'rb') as photo_file:\n",
    "                            self.bot.send_photo(\n",
    "                                message.chat.id,\n",
    "                                photo_file,\n",
    "                                caption=f\"Foto: {photo}\"\n",
    "                            )\n",
    "                    except Exception as e:\n",
    "                        print(f\"Erro ao enviar foto {photo}: {str(e)}\")\n",
    "                        continue\n",
    "                \n",
    "                self.bot.reply_to(message, \"‚úÖ Fotos enviadas! Para negociar, use /help para obter o contato do vendedor.\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.bot.reply_to(message, f\"Erro ao carregar as fotos: {str(e)}\")\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "        \n",
    "        @self.bot.message_handler(func=lambda message: True)\n",
    "        def handle_query(message):\n",
    "            if message.text.startswith('/'):\n",
    "                return\n",
    "                \n",
    "            chat_id = str(message.chat.id)\n",
    "            \n",
    "            # Verifica se est√° no modo chat\n",
    "            if message.chat.id not in self.chat_mode or not self.chat_mode[message.chat.id]:\n",
    "                response_text = (\n",
    "                    \"Ol√°! Para iniciar uma conversa comigo sobre o Siena 1.4 2010, use o comando /chat\\n\\n\"\n",
    "                    \"Outros comandos dispon√≠veis:\\n\"\n",
    "                    \"/Fotos - Ver fotos do ve√≠culo\\n\"\n",
    "                    \"/help - Contato do vendedor via WhatsApp\"\n",
    "                )\n",
    "                self.bot.reply_to(message, response_text)\n",
    "                return\n",
    "            \n",
    "            if not self.query_engine:\n",
    "                self.bot.reply_to(message, \n",
    "                    \"‚ùå Sistema n√£o inicializado. Aguarde um momento e tente novamente.\")\n",
    "                self.load_index()  # Tenta recarregar o √≠ndice\n",
    "                return\n",
    "            \n",
    "            try:\n",
    "                processing_msg = self.bot.reply_to(message, \"ü§î Processando sua pergunta...\")\n",
    "                \n",
    "                # Obt√©m resposta do LLM\n",
    "                response = self.query_engine.query(message.text)\n",
    "                response_text = str(response)\n",
    "                \n",
    "                # Atualiza hist√≥rico\n",
    "                if chat_id not in self.conversation_history:\n",
    "                    self.conversation_history[chat_id] = []\n",
    "                    \n",
    "                self.conversation_history[chat_id].append({\n",
    "                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    'question': message.text,\n",
    "                    'answer': response_text\n",
    "                })\n",
    "                \n",
    "                # Envia resposta\n",
    "                self.bot.edit_message_text(\n",
    "                    chat_id=message.chat.id,\n",
    "                    message_id=processing_msg.message_id,\n",
    "                    text=response_text,\n",
    "                    parse_mode='HTML'\n",
    "                )\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_msg = f\"‚ùå Erro ao processar pergunta: {str(e)}\"\n",
    "                self.bot.edit_message_text(\n",
    "                    chat_id=message.chat.id,\n",
    "                    message_id=processing_msg.message_id,\n",
    "                    text=error_msg\n",
    "                )\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"Inicia o bot\"\"\"\n",
    "        print(\"ü§ñ Bot iniciado...\")\n",
    "        self.bot.infinity_polling()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    BOT_TOKEN = bot_key #crie uma varieavel e adicione sua chave do telegram\n",
    "    bot = EnhancedTelegramBot(BOT_TOKEN)\n",
    "    bot.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
